# ğŸ—ï¸ AWS Serverless Data Lake â€” Stroke Risk Analytics

![AWS](https://img.shields.io/badge/AWS-Cloud-FF9900?style=flat&logo=amazon-aws)
![Terraform](https://img.shields.io/badge/Terraform-IaC-623CE4?style=flat&logo=terraform)
![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=flat&logo=python)
![Plotly](https://img.shields.io/badge/Plotly-Interactive-3F4F75?style=flat&logo=plotly)
![GitHub Pages](https://img.shields.io/badge/GitHub_Pages-Live-181717?style=flat&logo=github)

> **A production-grade, serverless data lake built on AWS to analyse stroke risk factors across 5,110 patient records â€” with interactive HTML dashboards hosted live on GitHub Pages.**

---

## ğŸŒ Live Dashboard

**[View Interactive Dashboards â†’](https://n-qobile.github.io/stroke-data-lake-aws/)**

No installation required. Navigate between tabs directly in your browser:
- ğŸ“Š **WHAT?** â€” Executive overview, KPIs, and key insights.
- ğŸ—ºï¸ **WHERE?** â€” Geographic analysis and urban vs rural disparities.
- ğŸ” **WHY?** â€” Risk factor analysis and comorbidity patterns.

---

## â­ Key Finding

> **Urban areas detect more strokes (5.2%) than rural areas (4.5%).**
>
> This suggests a diagnostic access gap â€” rural residents face barriers such as limited specialist availability, delayed diagnosis, and transportation challenges. This finding has direct implications for telehealth expansion and rural speech therapy resource allocation.

---

## ğŸ—ï¸ Architecture Overview

```
Kaggle Dataset (CSV)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRONZE LAYER                                            â”‚
â”‚  S3 Raw Bucket â†’ Glue Crawler â†’ Glue Data Catalogue      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL TRANSFORMATION                                      â”‚
â”‚  AWS Glue ETL Job (PySpark)                              â”‚
â”‚  â€¢ Deduplication  â€¢ BMI imputation  â€¢ Feature engineeringâ”‚
â”‚  â€¢ risk_score (0â€“20)  â€¢ Parquet output                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER LAYER                                            â”‚
â”‚  S3 Processed Bucket â†’ Glue Crawler â†’ Glue Catalogue     â”‚
â”‚  Apache Parquet  â€¢  Snappy compression                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ANALYTICS                                               â”‚
â”‚  Amazon Athena (Serverless SQL)  â€¢  5 analytical queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VISUALISATION  (GitHub Pages)                           â”‚
â”‚  Python Plotly â†’ Static HTML Export â†’ GitHub Pages       â”‚
â”‚  No backend server required  â€¢  Free hosting             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See `docs/architectural_diagrams/architecture-diagram.png` for the full visual diagram.

---

## ğŸ“ Project Structure

```
stroke-data-lake-aws/
â”‚
â”œâ”€â”€ terraform/                  # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ s3.tf
â”‚   â”œâ”€â”€ iam.tf
â”‚   â”œâ”€â”€ glue.tf
â”‚   â””â”€â”€ athena.tf
â”‚
â”œâ”€â”€ dashboard.py                # Dashboard generation
â”‚
â”œâ”€â”€ sql-queries/                # Analytical SQL queries
â”‚   â””â”€â”€ analysis_queries.sql
â”‚
â”œâ”€â”€ lambda/                     # Alternative ETL (not deployed)
â”‚   â””â”€â”€ transform_data.py
â”‚
â”œâ”€â”€ scripts/                     # Alternative Glue Script (not deployed)
â”‚   â””â”€â”€ glue_script_fixed.py
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ architecture-diagram.png
â”‚   â””â”€â”€ technical-report.md
|   â””â”€â”€ deployment-guide.md
â”‚   â””â”€â”€screenshots/                # Evidence: queries & AWS services
|
â”œâ”€â”€ index.html                  # Dashboard tab navigation (GitHub Pages)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ”¬ Dataset

| Attribute | Detail |
|-----------|--------|
| Source | Kaggle Stroke Prediction Dataset |
| Records | 5,110 patients |
| Original format | CSV (semicolon-delimited) |
| Processed format | Apache Parquet (Snappy compressed) |
| Enhanced columns | age_group, bmi_category, glucose_category, risk_score |

---

## ğŸ“Š Key Results

| Finding | Data | Implication |
|---------|------|-------------|
| Urban vs Rural Detection | 5.2% vs 4.5% | Healthcare access gap |
| Highest Risk Age Group | 75+ (43 cases) | Priority for services |
| Average Risk Score | 5.3 out of 20 | Moderate risk population |
| Comorbidity Rate | HTN + HD + Smoking = 18.5% | Compounding effect |
| SLP Demand | ~174 patients | ~2,088 therapy sessions needed |

---

## ğŸ¨ Dashboard Colour System

The dashboard uses an intentional colour palette grounded in **speech therapy semantic cueing principles** â€” each colour reinforces the meaning of its tab rather than applying a generic "traffic light" system.

| Colour | Hex | Purpose |
|--------|-----|---------|
| ğŸŸ£ Stroke Purple | `#7C3AED` | Clinical credibility â€” primary brand across all tabs |
| ğŸ”´ Stroke Red Ribbon | `#EF4444` | International stroke awareness symbol |
| ğŸ”µ Electric Blue | `#3B82F6` | Geographic/systems thinking â€” WHERE? tab |
| ğŸŸ¢ Lime Green | `#84CC16` | Rural/environmental context â€” WHERE? tab |
| ğŸŸ  Vivid Orange | `#F97316` | Risk mechanisms and causation â€” WHY? tab |

**Why not the standard "green = good, red = bad" system?**

Traditional medical dashboards oversimplify complex healthcare data with traffic-light colours. This approach assigns each tab a thematic colour that reinforces its analytical purpose â€” making the dashboard more memorable, accessible, and analytically sophisticated. High contrast ratios also support accessibility for stroke survivors with visual deficits.

---

## ğŸ—£ï¸ Speech Therapy Relevance

As a speech therapist, this project bridges clinical knowledge and cloud engineering:

- **70% of stroke survivors** require speech and language therapy (SLP) services.
- **~174 patients** in this dataset are estimated to need SLP intervention.
- **~2,088 sessions** are required based on an average of 12 sessions per patient.
- **Priority population:** Urban residents aged 75+ (highest stroke detection rate).
- **Rural gap:** Telehealth expansion is recommended to address the 0.7 percentage point detection disparity.

---

## ğŸ› ï¸ Technologies Used

| Category | Technology |
|----------|-----------|
| Cloud Platform | Amazon Web Services (AWS) |
| Infrastructure | Terraform (IaC) |
| Storage | Amazon S3 |
| ETL | AWS Glue (PySpark) |
| Data Catalogue | AWS Glue Data Catalogue |
| Analytics | Amazon Athena (Presto SQL) |
| Visualisation | Python, Plotly (exported to static HTML) |
| Hosting | GitHub Pages |
| Version Control | Git / GitHub |
| Language | Python 3.9+ |

---

## ğŸ’° Cost

| Service | Monthly Cost |
|---------|-------------|
| Amazon S3 (3 buckets, ~1 GB) | ~Â£0.02 |
| Amazon Athena (100 queries) | ~Â£0.01 |
| AWS Glue ETL (manual) | Â£0.00 |
| GitHub Pages (hosting) | Â£0.00 |
| **Total** | **~Â£0.04/month** |

Costs are minimised through Parquet compression (80% less data scanned), manual crawler execution, and S3 lifecycle policies.

---

## ğŸš€ Deployment

### Prerequisites
- AWS account with appropriate IAM permissions.
- Python 3.9+.

### Steps

```bash
# 1. Clone the repository
git clone https://github.com/n-qobile/stroke-data-lake-aws.git
cd stroke-data-lake-aws

# 2. Deploy infrastructure
cd terraform
terraform init
terraform plan
terraform apply

# 3. Upload raw data to S3
aws s3 cp data/raw/healthcare-dataset-stroke-data.csv \
    s3://stroke-data-lake-raw-data-ACCOUNT_ID/

# 4. Run Glue ETL job (via AWS Console or CLI)

# 5. Generate dashboards
cd dashboards
python dashboard_enhanced.py
# This creates index.html and 3 tab HTML files

# 6. Commit HTML files and enable GitHub Pages
git add index.html *.html
git commit -m "Add: Dashboard HTML files for GitHub Pages"
git push
# Then: GitHub repo â†’ Settings â†’ Pages â†’ Source: main branch â†’ Save
```

---

## ğŸ“¸ Screenshots

See the `screenshots/` folder for:
- AWS Console: S3 buckets, Glue job, Glue catalogue, Athena workgroup.
- Athena query results (5 analytical queries with CSVs).

---

## ğŸ“„ Documentation

- [`docs/architectural_diagrams/architecture-diagram.png`](docs/architectural_diagrams/architecture-diagram.png) â€” Full system architecture
- [`docs/technical-report.md`](docs/technical-report.md) â€” 3-page technical report

---

## ğŸ‘©â€ğŸ’» Author

**Created by Nqobile M**
Speech Therapist & Cloud Data Engineer | February 2026

---

